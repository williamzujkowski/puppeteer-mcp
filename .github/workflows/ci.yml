name: CI Pipeline

on:
  push:
    branches: [main, develop, 'release/*', 'hotfix/*']
  pull_request:
    branches: [main, develop, 'release/*']
  merge_group:
    branches: [main]

permissions:
  contents: read
  security-events: write
  actions: read
  pull-requests: write
  checks: write

env:
  NODE_ENV: test
  CI: true
  FORCE_COLOR: 3
  USE_DATA_URLS: true
  SUPPRESS_TEST_LOGS: true

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  # Quality gates and checks
  quality-gates:
    name: Quality Gates
    runs-on: ubuntu-latest
    outputs:
      breaking-changes: ${{ steps.breaking.outputs.has-breaking-changes }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --prefer-offline --no-audit --legacy-peer-deps

      - name: Check for breaking changes
        id: breaking
        run: |
          # Check commit messages for breaking changes
          if git log --format=%B origin/main..HEAD | grep -q "BREAKING CHANGE:\|!:"; then
            echo "has-breaking-changes=true" >> $GITHUB_OUTPUT
            echo "⚠️ Breaking changes detected in commits"
          else
            echo "has-breaking-changes=false" >> $GITHUB_OUTPUT
          fi

      - name: Validate commit messages
        run: |
          # Install commitlint
          npm install -g @commitlint/cli @commitlint/config-conventional

          # Validate commits
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            npx commitlint --from ${{ github.event.pull_request.head.sha }}~${{ github.event.pull_request.commits }} --to ${{ github.event.pull_request.head.sha }}
          fi

  # Code quality checks
  code-quality:
    name: Code Quality - Node.js ${{ matrix.node-version }}
    runs-on: ubuntu-latest
    strategy:
      matrix:
        node-version: ['20.x', '22.x']
      fail-fast: false

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --prefer-offline --no-audit --legacy-peer-deps

      - name: Lint code
        run: |
          npm run lint -- --format json --output-file eslint-report.json || true
          npm run lint -- --max-warnings 1200

      - name: Type check
        run: npm run typecheck

      - name: Check code formatting
        run: npm run format:check

      - name: Standards compliance
        run: npm run standards:check

      - name: Upload lint results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: lint-results-node-${{ matrix.node-version }}
          path: eslint-report.json
          retention-days: 7

  # Test suite with coverage
  test-suite:
    name: Test Suite - Node.js ${{ matrix.node-version }}
    runs-on: ubuntu-latest
    needs: code-quality
    strategy:
      matrix:
        node-version: ['20.x', '22.x']
      fail-fast: false

    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'

      - name: Install Chrome
        uses: browser-actions/setup-chrome@latest
        with:
          chrome-version: stable

      - name: Install dependencies
        run: npm ci --prefer-offline --no-audit --legacy-peer-deps

      - name: Build project
        run: npm run build

      - name: Run unit tests with coverage
        run: npm run test:ci
        env:
          JEST_JUNIT_OUTPUT_DIR: ./test-results
          JEST_JUNIT_OUTPUT_NAME: junit-unit-${{ matrix.node-version }}.xml
          PUPPETEER_EXECUTABLE_PATH: /usr/bin/google-chrome-stable

      - name: Run integration tests
        run: npm run test:integration -- --ci --reporters=default --reporters=jest-junit
        env:
          JEST_JUNIT_OUTPUT_DIR: ./test-results
          JEST_JUNIT_OUTPUT_NAME: junit-integration-${{ matrix.node-version }}.xml
          REDIS_URL: redis://localhost:6379
          PUPPETEER_EXECUTABLE_PATH: /usr/bin/google-chrome-stable

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-node-${{ matrix.node-version }}
          path: |
            ./test-results/
            ./coverage/
          retention-days: 7

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          flags: unittests,node-${{ matrix.node-version }}
          name: node-${{ matrix.node-version }}
          files: ./coverage/lcov.info
          fail_ci_if_error: false

  # Performance benchmarks
  performance-benchmarks:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    needs: test-suite
    if: github.event_name == 'push' || github.event_name == 'pull_request'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --prefer-offline --no-audit --legacy-peer-deps

      - name: Build project
        run: npm run build

      - name: Run performance benchmarks
        run: |
          # Create benchmarks directory if it doesn't exist
          mkdir -p benchmarks

          # Run performance tests
          cat > benchmarks/run-benchmarks.js << 'EOF'
          import { performance } from 'perf_hooks';
          import { BrowserPool } from '../dist/puppeteer/pool/browser-pool.js';

          async function runBenchmarks() {
            console.log('Running performance benchmarks...\n');
            
            // Browser pool initialization benchmark
            const startInit = performance.now();
            const pool = new BrowserPool({ size: 5 });
            await pool.initialize();
            const initTime = performance.now() - startInit;
            
            console.log(`Browser pool initialization: ${initTime.toFixed(2)}ms`);
            
            // Browser acquisition benchmark
            const acquisitionTimes = [];
            for (let i = 0; i < 10; i++) {
              const startAcquire = performance.now();
              const browser = await pool.acquire();
              const acquireTime = performance.now() - startAcquire;
              acquisitionTimes.push(acquireTime);
              await pool.release(browser);
            }
            
            const avgAcquisition = acquisitionTimes.reduce((a, b) => a + b, 0) / acquisitionTimes.length;
            console.log(`Average browser acquisition: ${avgAcquisition.toFixed(2)}ms`);
            
            // Cleanup
            await pool.shutdown();
            
            // Save results
            const results = {
              timestamp: new Date().toISOString(),
              initializationTime: initTime,
              averageAcquisitionTime: avgAcquisition,
              nodeVersion: process.version,
              commit: process.env.GITHUB_SHA || 'local'
            };
            
            require('fs').writeFileSync(
              'benchmarks/results.json',
              JSON.stringify(results, null, 2)
            );
          }

          runBenchmarks().catch(console.error);
          EOF

          node benchmarks/run-benchmarks.js || echo "Benchmarks completed with warnings"

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: benchmarks/results.json
          retention-days: 30

      - name: Comment PR with benchmark results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const results = JSON.parse(fs.readFileSync('benchmarks/results.json', 'utf8'));

            const comment = `## 🚀 Performance Benchmark Results

            | Metric | Value |
            |--------|-------|
            | Browser Pool Initialization | ${results.initializationTime.toFixed(2)}ms |
            | Average Browser Acquisition | ${results.averageAcquisitionTime.toFixed(2)}ms |
            | Node Version | ${results.nodeVersion} |
            `;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

  # Security scanning
  security-scanning:
    name: Security Scanning
    runs-on: ubuntu-latest
    needs: code-quality

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@0.32.0
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH,MEDIUM'

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'

      - name: Run npm audit
        run: |
          npm audit --production --json > npm-audit.json || true

          # Parse audit results
          node -e "
            const audit = require('./npm-audit.json');
            const vulns = audit.metadata.vulnerabilities;
            console.log('NPM Audit Summary:');
            console.log(\`- Critical: \${vulns.critical}\`);
            console.log(\`- High: \${vulns.high}\`);
            console.log(\`- Moderate: \${vulns.moderate}\`);
            console.log(\`- Low: \${vulns.low}\`);
            
            if (vulns.critical > 0 || vulns.high > 0) {
              console.error('\\n❌ Critical or high vulnerabilities found!');
              process.exit(1);
            }
          "

      - name: Upload audit results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-audit
          path: |
            npm-audit.json
            trivy-results.sarif
          retention-days: 30

  # Build verification
  build-verification:
    name: Build Verification
    runs-on: ubuntu-latest
    needs: [test-suite, security-scanning]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --prefer-offline --no-audit --legacy-peer-deps

      - name: Build project
        run: npm run build

      - name: Verify build output
        run: |
          # Check build directory exists
          if [ ! -d "dist" ]; then
            echo "❌ Build failed: dist directory not found"
            exit 1
          fi

          # Check key files exist
          for file in "server.js" "cli/index.js" "mcp/start-mcp.js"; do
            if [ ! -f "dist/$file" ]; then
              echo "❌ Build failed: dist/$file not found"
              exit 1
            fi
          done

          # Check TypeScript declarations
          find dist -name "*.d.ts" | head -5

          echo "✅ Build verification passed"

      - name: Test global installation
        run: |
          # Pack the package
          npm pack

          # Install globally in a temp directory
          export NPM_CONFIG_PREFIX=$(mktemp -d)
          export PATH="$NPM_CONFIG_PREFIX/bin:$PATH"

          npm install -g puppeteer-mcp-*.tgz

          # Test CLI command
          puppeteer-mcp --version

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: |
            dist/
            *.tgz
          retention-days: 7

  # Docker build and scan
  docker-validation:
    name: Docker Validation
    runs-on: ubuntu-latest
    needs: build-verification

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build Docker image
        uses: docker/build-push-action@v6
        with:
          context: .
          load: true
          tags: puppeteer-mcp:ci
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Run Trivy on Docker image
        uses: aquasecurity/trivy-action@0.32.0
        with:
          image-ref: 'puppeteer-mcp:ci'
          format: 'sarif'
          output: 'docker-trivy-results.sarif'
          severity: 'CRITICAL,HIGH'

      - name: Test Docker image
        run: |
          # Run container and check health
          docker run -d --name test-container \
            -p 3000:3000 \
            -e NODE_ENV=production \
            puppeteer-mcp:ci
            
          # Wait for startup
          sleep 10

          # Check health endpoint
          curl -f http://localhost:3000/api/v1/health || exit 1

          # Cleanup
          docker stop test-container
          docker rm test-container

      - name: Upload Docker scan results
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: 'docker-trivy-results.sarif'

  # Final status check
  ci-status:
    name: CI Status Check
    runs-on: ubuntu-latest
    needs:
      [
        quality-gates,
        code-quality,
        test-suite,
        security-scanning,
        build-verification,
        docker-validation,
      ]
    if: always()

    steps:
      - name: Check CI status
        run: |
          # This job succeeds only if all required jobs succeed
          if [ "${{ needs.quality-gates.result }}" != "success" ] ||
             [ "${{ needs.code-quality.result }}" != "success" ] ||
             [ "${{ needs.test-suite.result }}" != "success" ] ||
             [ "${{ needs.security-scanning.result }}" != "success" ] ||
             [ "${{ needs.build-verification.result }}" != "success" ] ||
             [ "${{ needs.docker-validation.result }}" != "success" ]; then
            echo "❌ CI pipeline failed"
            exit 1
          fi

          echo "✅ All CI checks passed successfully!"
